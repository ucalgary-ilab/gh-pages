<!DOCTYPE html><html><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="format-detection" content="telephone=no"/><link href="https://use.fontawesome.com/releases/v5.1.1/css/all.css" rel="stylesheet"/><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.css" rel="stylesheet"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/css/lightbox.css" rel="stylesheet"/><link href="/assets/img/favicon.ico" rel="shortcut icon"/><link href="/static/css/style.css" rel="stylesheet"/><script src="https://code.jquery.com/jquery-3.2.1.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lightbox2/2.11.0/js/lightbox-plus-jquery.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/semantic-ui/2.4.0/semantic.js"></script><script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-62643728-2"></script><script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
            gtag('config', 'UA-62643728-2');
          </script><script>
            $(window).ready(function() {
              $('.ui.sidebar')
                .sidebar('attach events', '.sidebar.icon')

              $('.publication').on('click', function(event) {
                if (event.target.className === 'author-link') return
                const id = this.dataset.id
                $('#'+id).modal({
                  onHidden: function() {
                    const html = $(this).html()
                    $(this).html(html)
                  }
                })
                .modal('show')
              })
            })
          </script><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1" class="next-head"/><meta charSet="utf-8" class="next-head"/><title class="next-head">Aditya Shekhar Nittala | Interactions Lab - University of Calgary HCI Group</title><meta name="keywords" content="Human-Computer Interaction, HCI, Information Visualization, University of Calgary, CHI, UIST" class="next-head"/><meta name="description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" class="next-head"/><meta property="og:title" content="Aditya Shekhar Nittala | Interactions Lab - University of Calgary HCI Group" class="next-head"/><meta property="og:description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" class="next-head"/><meta property="og:site_name" content="University of Calgary Interactions Lab" class="next-head"/><meta property="og:url" content="https://ilab.ucalgary.ca/" class="next-head"/><meta property="og:image" content="https://ilab.ucalgary.ca/static/images/people/aditya-shekhar-nittala.jpg" class="next-head"/><meta property="og:type" content="website" class="next-head"/><meta name="twitter:title" content="Aditya Shekhar Nittala | Interactions Lab - University of Calgary HCI Group" class="next-head"/><meta name="twitter:description" content="Human-Computer Interaction and Information Visualization Group at the University of Calgary" class="next-head"/><meta name="twitter:image" content="https://ilab.ucalgary.ca/static/images/people/aditya-shekhar-nittala.jpg" class="next-head"/><meta name="twitter:card" content="summary" class="next-head"/><meta name="twitter:site" content="@ucalgary" class="next-head"/><meta name="twitter:url" content="https://ilab.ucalgary.ca/" class="next-head"/><link rel="preload" href="/_next/static/YZs1ac8e0ztJgB9CAEqPq/pages/person.js" as="script"/><link rel="preload" href="/_next/static/YZs1ac8e0ztJgB9CAEqPq/pages/_app.js" as="script"/><link rel="preload" href="/_next/static/runtime/webpack-8ed9452df514b4d17d80.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.dd9f0e26319bf7824a67.js" as="script"/><link rel="preload" href="/_next/static/runtime/main-f4b43c249e4a4370cde3.js" as="script"/></head><body><div id="__next"><div><div><div class="ui right vertical sidebar menu"><a class="item" href="/">Home</a><a class="item" href="/publications">Publications</a><a class="item active" href="/people">People</a><a class="item" href="/courses">Courses</a><a class="item" href="/facility">Facility</a><a class="item" href="/seminar">Seminar</a><a class="item" href="/location">Location</a></div><div class="ui stackable secondary pointing container menu" style="border-bottom:none;margin-right:15%;font-size:1.1em"><div class="left menu"><a class="item" href="/"><b>UCalgary iLab</b></a></div><div class="right menu"><a class="item" href="/publications">Publications</a><a class="item active" href="/people">People</a><a class="item" href="/courses">Courses</a><a class="item" href="/facility">Facility</a><a class="item" href="/seminar">Seminar</a><a class="item" href="/location">Location</a><div class="toc item"><a href="/"><b>UCalgary iLab</b></a><i style="float:right" class="sidebar icon"></i></div></div></div></div><div class="ui stackable grid"><div class="one wide column"></div><div class="eleven wide column centered"><div id="person" class="category" style="text-align:center"><img class="ui circular image large-profile" src="/static/images/people/aditya-shekhar-nittala.jpg" style="margin:auto"/><h1>Aditya Shekhar Nittala</h1><p>Assistant Professor</p><p><a href="https://sites.google.com/site/adityanittala/" target="_blank"><i class="fas fa-link fa-fw"></i>https://sites.google.com/site/adityanittala/</a></p><p><a href="https://scholar.google.com/citations?user=pDSbjBsAAAAJ" target="_blank"><i class="fas fa-graduation-cap fa-fw"></i>Google Scholar</a></p><div class="ui horizontal small divided link list"><div class="item"><a href="https://www.linkedin.com/in/adityashekharn" target="_blank" style="font-size:1.2em"><i class="fab fa-linkedin-in fa-fw"></i>LinkedIn</a></div><div class="item"><a href="anittala@ucalgary.ca" target="_blank" style="font-size:1.2em"><i class="far fa-envelope fa-fw"></i>anittala@ucalgary.ca</a></div></div></div><div id="publications" class="category"><h1 class="ui horizontal divider header"><i class="file alternate outline icon"></i>Publications</h1><div class="ui segment" style="margin-top:50px"><div class="publication ui vertical segment stackable grid" data-id="tochi-2022-nittala"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/tochi-2022-nittala.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">TOCHI 2022</span></p><p class="color" style="font-size:1.3em"><b>SparseIMU: Computational Design of Sparse IMU Layouts for Sensing Fine-Grained Finger Microgestures</b></p><p><span>Adwait Sharma</span> , <span>Christina Salchow-Hömmen</span> , <span>Vimal Suresh Mollyn</span> , <a href="/people/aditya-shekhar-nittala"><img src="/static/images/people/aditya-shekhar-nittala.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Aditya Shekhar Nittala</span></a> , <span>Michael A. Hedderich</span> , <span>Marion Koelle</span> , <span>Thomas Seel</span> , <span>Jürgen Steimle</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Gesture Recognition</span><span class="ui brown basic label">Hand Gestures</span><span class="ui brown basic label">Sensor Placement</span><span class="ui brown basic label">IMU</span><span class="ui brown basic label">Objects</span><span class="ui brown basic label">Design Tool</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="uist-2022-nittala"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/uist-2022-nittala.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">UIST 2022</span><span class="ui big basic pink label"><b><i class="fas fa-trophy"></i> Best Paper</b></span></p><p class="color" style="font-size:1.3em"><b>Prototyping Soft Devices with Interactive Bioplastics</b></p><p><span>Marion Koelle</span> , <span>Madalina Nicolae</span> , <a href="/people/aditya-shekhar-nittala"><img src="/static/images/people/aditya-shekhar-nittala.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Aditya Shekhar Nittala</span></a> , <span>Marc Teyssier</span> , <span>Jürgen Steimle</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Bioplastics</span><span class="ui brown basic label">Biomaterials</span><span class="ui brown basic label">Do It Yourself</span><span class="ui brown basic label">DIY</span><span class="ui brown basic label">Sustainability</span></div></p></div></div><div class="publication ui vertical segment stackable grid" data-id="chi-2022-nittala"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2022-nittala.jpg"/></div><div class="thirteen wide column"><p><span class="ui big inverted label label-color">CHI 2022</span></p><p class="color" style="font-size:1.3em"><b>Next Steps in Epidermal Computing: Opportunities and Challenges for Soft On-Skin Devices</b></p><p><a href="/people/aditya-shekhar-nittala"><img src="/static/images/people/aditya-shekhar-nittala.jpg" class="ui circular spaced image mini-profile"/><span class="author-link">Aditya Shekhar Nittala</span></a> , <span>Jürgen Steimle</span></p><p><div class="ui large basic labels"><span class="ui brown basic label">Wearable Devices</span><span class="ui brown basic label">Epidermal Devices</span><span class="ui brown basic label">Survey</span><span class="ui brown basic label">Soft Wearables</span></div></p></div></div></div><div id="publications-modal"><div id="tochi-2022-nittala" class="ui large modal"><div class="header"><a href="/publications/tochi-2022-nittala" target="_blank"><i class="fas fa-link fa-fw"></i>tochi-2022-nittala</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">TOCHI 2022</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/tochi-2022-nittala.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/tochi-2022-nittala" target="_blank">SparseIMU: Computational Design of Sparse IMU Layouts for Sensing Fine-Grained Finger Microgestures</a></h1><p class="meta"><span>Adwait Sharma</span> , <span>Christina Salchow-Hömmen</span> , <span>Vimal Suresh Mollyn</span> , <a href="/people/aditya-shekhar-nittala"><img src="/static/images/people/aditya-shekhar-nittala.jpg" class="ui circular spaced image mini-profile"/><strong>Aditya Shekhar Nittala</strong></a> , <span>Michael A. Hedderich</span> , <span>Marion Koelle</span> , <span>Thomas Seel</span> , <span>Jürgen Steimle</span></p><p><a href="/static/publications/tochi-2022-nittala.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>tochi-2022-nittala.pdf</a></p></div></div></div><div class="block"><h1>Abstract</h1><p>Gestural interaction with freehands and while grasping an everyday object enables always-available input. To sense such gestures, minimal instrumentation of the user’s hand is desirable. However, the choice of an effective but minimal IMU layout remains challenging, due to the complexity of the multi-factorial space that comprises diverse finger gestures, objects and grasps. We present SparseIMU, a rapid method for selecting minimal inertial sensor-based layouts for effective gesture recognition. Furthermore, we contribute a computational tool to guide designers with optimal sensor placement. Our approach builds on an extensive microgestures dataset that we collected with a dense network of 17 inertial measurement units (IMUs). We performed a series of analyses, including an evaluation of the entire combinatorial space for freehand and grasping microgestures (393K layouts), and quantified the performance across different layout choices, revealing new gesture detection opportunities with IMUs. Finally, we demonstrate the versatility of our method with four scenarios.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Gesture Recognition</span><span class="ui brown basic label">Hand Gestures</span><span class="ui brown basic label">Sensor Placement</span><span class="ui brown basic label">IMU</span><span class="ui brown basic label">Objects</span><span class="ui brown basic label">Design Tool</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Adwait Sharma<!-- -->, <!-- -->Christina Salchow-Hömmen<!-- -->, <!-- -->Vimal Suresh Mollyn<!-- -->, <!-- -->Aditya Shekhar Nittala<!-- -->, <!-- -->Michael A. Hedderich<!-- -->, <!-- -->Marion Koelle<!-- -->, <!-- -->Thomas Seel<!-- -->, <!-- -->Jürgen Steimle<!-- -->. <b>SparseIMU: Computational Design of Sparse IMU Layouts for Sensing Fine-Grained Finger Microgestures</b>. <i>In undefined (TOCHI &#x27;22)</i>. <!-- -->  Page: 1-<!-- -->40<!-- -->.  DOI: <a href="https://doi.org/10.1145/3569894" target="_blank">https://doi.org/10.1145/3569894</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="uist-2022-nittala" class="ui large modal"><div class="header"><a href="/publications/uist-2022-nittala" target="_blank"><i class="fas fa-link fa-fw"></i>uist-2022-nittala</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">UIST 2022</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/uist-2022-nittala.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/uist-2022-nittala" target="_blank">Prototyping Soft Devices with Interactive Bioplastics</a></h1><p class="meta"><span>Marion Koelle</span> , <span>Madalina Nicolae</span> , <a href="/people/aditya-shekhar-nittala"><img src="/static/images/people/aditya-shekhar-nittala.jpg" class="ui circular spaced image mini-profile"/><strong>Aditya Shekhar Nittala</strong></a> , <span>Marc Teyssier</span> , <span>Jürgen Steimle</span></p><p><a href="/static/publications/uist-2022-nittala.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>uist-2022-nittala.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/8Paq3P3EsKQ" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/8Paq3P3EsKQ?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/8Paq3P3EsKQ/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Designers and makers are increasingly interested in leveraging bio-based and bio-degradable ‘do-it-yourself’ (DIY) materials for sustainable prototyping. Their self-produced bioplastics possess compelling properties such as self-adhesion but have so far not been functionalized to create soft interactive devices, due to a lack of DIY techniques for the fabrication of functional electronic circuits and sensors. In this paper, we contribute a DIY approach for creating Interactive Bioplastics that is accessible to a wide audience, making use of easy-to-obtain bio-based raw materials and familiar tools. We present three types of conductive bioplastic materials and their formulation: sheets, pastes and foams. Our materials enable additive and subtractive fabrication of soft circuits and sensors. Furthermore, we demonstrate how these materials can substitute conventional prototyping materials, be combined with off-the-shelf electronics, and be fed into a sustainable material ‘life-cycle’ including disassembly, re-use, and re-melting of materials. A formal characterization of our conductors highlights that they are even on-par with commercially available carbon-based conductive pastes.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Bioplastics</span><span class="ui brown basic label">Biomaterials</span><span class="ui brown basic label">Do It Yourself</span><span class="ui brown basic label">DIY</span><span class="ui brown basic label">Sustainability</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Marion Koelle<!-- -->, <!-- -->Madalina Nicolae<!-- -->, <!-- -->Aditya Shekhar Nittala<!-- -->, <!-- -->Marc Teyssier<!-- -->, <!-- -->Jürgen Steimle<!-- -->. <b>Prototyping Soft Devices with Interactive Bioplastics</b>. <i>In Proceedings of the Annual ACM Symposium on User Interface Software and Technology (UIST &#x27;22)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->16<!-- -->.  DOI: <a href="https://doi.org/10.1145/3526113.3545623" target="_blank">https://doi.org/10.1145/3526113.3545623</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div><div id="chi-2022-nittala" class="ui large modal"><div class="header"><a href="/publications/chi-2022-nittala" target="_blank"><i class="fas fa-link fa-fw"></i>chi-2022-nittala</a><div class="actions" style="float:right;cursor:pointer;color:grey"><i class="ui right cancel close icon"></i></div></div><div class="content"><div id="publication"><div class="block"><div id="breadcrumb" class="ui breadcrumb"><a class="section" href="/publications">Publications</a><i class="right angle icon divider"></i><a class="active section">CHI 2022</a></div><div class="ui stackable grid" style="margin-top:10px"><div class="three wide column" style="margin:auto"><img class="cover" src="/static/images/publications/cover/chi-2022-nittala.jpg"/></div><div class="thirteen wide column"><h1><a href="/publications/chi-2022-nittala" target="_blank">Next Steps in Epidermal Computing: Opportunities and Challenges for Soft On-Skin Devices</a></h1><p class="meta"><a href="/people/aditya-shekhar-nittala"><img src="/static/images/people/aditya-shekhar-nittala.jpg" class="ui circular spaced image mini-profile"/><strong>Aditya Shekhar Nittala</strong></a> , <span>Jürgen Steimle</span></p><p><a href="/static/publications/chi-2022-nittala.pdf" target="_blank"><i class="far fa-file-pdf fa-fw"></i>chi-2022-nittala.pdf</a></p></div></div></div><div class="block"><div class="video-container"><iframe class="embed" width="100%" height="315" src="https://www.youtube.com/embed/Lj9Yk5IQsok" srcDoc="&lt;style&gt;*{padding:0;margin:0;overflow:hidden}html,body{height:100%}img,span{position:absolute;width:100%;top:0;bottom:0;margin:auto}span{height:1.5em;text-align:center;font:48px/1.5 sans-serif;color:white;text-shadow:0 0 0.5em black}&lt;/style&gt;&lt;a href=https://www.youtube.com/embed/Lj9Yk5IQsok?autoplay=1&gt;&lt;img src=https://img.youtube.com/vi/Lj9Yk5IQsok/maxresdefault.jpg&gt;&lt;span&gt;▶&lt;/span&gt;&lt;/a&gt;" frameBorder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" mozallowfullscreen="true" msallowfullscreen="true" oallowfullscreen="true" webkitallowfullscreen="true"></iframe></div></div><div class="block"><h1>Abstract</h1><p>Skin is a promising interaction medium and has been widely explored for mobile, and expressive interaction. Recent research in HCI has seen the development of Epidermal Computing Devices: ultra-thin and non-invasive devices which reside on the user’s skin, offering intimate integration with the curved surfaces of the body, while having physical and mechanical properties that are akin to skin, expanding the horizon of on-body interaction. However, with rapid technological advancements in multiple disciplines, we see a need to synthesize the main open research questions and opportunities for the HCI community to advance future research in this area. By systematically analyzing Epidermal Devices contributed in the HCI community, physical sciences research and from our experiences in designing and building Epidermal Devices, we identify opportunities and challenges for advancing research across five themes. This multi-disciplinary synthesis enables multiple research communities to facilitate progression towards more coordinated endeavors for advancing Epidermal Computing.</p><div class="ui large basic labels">Keywords:  <span class="ui brown basic label">Wearable Devices</span><span class="ui brown basic label">Epidermal Devices</span><span class="ui brown basic label">Survey</span><span class="ui brown basic label">Soft Wearables</span></div></div><div class="block"><h1>Reference</h1><div class="ui segment"><p style="line-height:160%">Aditya Shekhar Nittala<!-- -->, <!-- -->Jürgen Steimle<!-- -->. <b>Next Steps in Epidermal Computing: Opportunities and Challenges for Soft On-Skin Devices</b>. <i>In Proceedings of the CHI Conference on Human Factors in Computing Systems (CHI &#x27;22)</i>. <!-- -->ACM, New York, NY, USA<!-- -->  Page: 1-<!-- -->22<!-- -->.  DOI: <a href="https://doi.org/10.1145/3491102.3517668" target="_blank">https://doi.org/10.1145/3491102.3517668</a></p></div></div></div></div><div class="actions"><div class="ui right cancel button">Close</div></div></div></div></div></div><div class="one wide column"></div></div><footer><div class="ui center aligned container"><div class="ui section divider"></div><img style="max-width:180px;margin:30px auto" src="/static/images/logo-6.png"/><div class="content"><img style="max-width:200px;margin:0px auto" src="/static/images/logo-4.png"/><div class="sub header">Department of Computer Science</div></div></div></footer></div></div><script id="__NEXT_DATA__" type="application/json">{"dataManager":"[]","props":{"pageProps":{"id":"aditya-shekhar-nittala"}},"page":"/person","query":{"id":"aditya-shekhar-nittala"},"buildId":"YZs1ac8e0ztJgB9CAEqPq","dynamicBuildId":false,"nextExport":true}</script><script async="" id="__NEXT_PAGE__/person" src="/_next/static/YZs1ac8e0ztJgB9CAEqPq/pages/person.js"></script><script async="" id="__NEXT_PAGE__/_app" src="/_next/static/YZs1ac8e0ztJgB9CAEqPq/pages/_app.js"></script><script src="/_next/static/runtime/webpack-8ed9452df514b4d17d80.js" async=""></script><script src="/_next/static/chunks/commons.dd9f0e26319bf7824a67.js" async=""></script><script src="/_next/static/runtime/main-f4b43c249e4a4370cde3.js" async=""></script></body></html>